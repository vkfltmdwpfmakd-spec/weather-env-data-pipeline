services:
    postgres:
        image: postgres:13
        container_name: postgres_db
        environment: # 환경변수
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        ports:
            - "5432:5432" #  로컬 접근 포트
        volumes:
            - postgres_data:/var/lib/postgresql/data # 컨테이너가 삭제되어도 데이터를 보존하기 위해 Docker 볼륨과 연결
    
    minio:
        image: minio/minio:latest
        container_name: minio_storage
        ports:
            - "9000:9000" # S3 API 포트
            - "9001:9001" # minio 웹 UI 포트
        environment:
            - MINIO_ROOT_USER=minio
            - MINIO_ROOT_PASSWORD=minio1234
        # MinIO 서버를 실행하는 명령어. /data 디렉토리를 스토리지로 사용하고, 9001 포트에서 웹 UI를 실행
        command: server /data --console-address ":9001"
        volumes:
            - minio_data:/data # 컨테이너가 삭제되어도 데이터를 보존하기 위해 Docker 볼륨과 연결
    
    airflow-webserver:
        build: . # Dockerfile을 사용해 이미지 빌드
        container_name: airflow_webserver
        depends_on: # 의존성 , postgres 서비스가 먼저 실행되어야 함
            - postgres
            - minio
        environment:
            - AIRFLOW__CORE__EXECUTOR=LocalExecutor # Airflow가 작업을 실행하는 방식 (LocalExecutor는 단일 노드에서 병렬 처리)
            - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres_db:5432/airflow # Airflow 메타데이터 DB 연결 정보. 'postgres'는 위에서 정의한 서비스 이름
            - AIRFLOW__WEBSERVER__SECRET_KEY=secretkey # 웹 UI 보안을 위한 임의의 시크릿 키
        volumes:
            - ./dags:/opt/airflow/dags       # 로컬의 dags 폴더를 컨테이너의 dags 폴더와 동기화 (DAG 파일 관리)
            - ./plugins:/opt/airflow/plugins # 로컬의 plugins 폴더를 컨테이너의 plugins 폴더와 동기화
            - ./data:/opt/airflow/data       # 로컬의 data 폴더를 컨테이너의 data 폴더와 동기화 (데이터 임시 저장)
            - ./dbt/weather_project:/opt/airflow/dbt/weather_project # 로컬의 dbt 폴더를 컨테이너의 dbt 폴더와 동기화 (dbt 프로젝트 관리)
            - ./dbt/profiles:/home/airflow/.dbt 
            - ./notebooks/gx:/opt/airflow/gx # Great Expectations 프로젝트 공유
        ports:
            - "8080:8080"
        command: webserver

    airflow-scheduler:
        build: . # Dockerfile을 사용해 이미지 빌드
        container_name: airflow_scheduler
        depends_on:
            - postgres
            - minio
        environment:
            - AIRFLOW__CORE__EXECUTOR=LocalExecutor
            - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres_db:5432/airflow
            - AIRFLOW__WEBSERVER__SECRET_KEY=secretkey
        volumes:
            - ./dags:/opt/airflow/dags
            - ./logs:/opt/airflow/logs
            - ./plugins:/opt/airflow/plugins
            - ./data:/opt/airflow/data
            - ./dbt/weather_project:/opt/airflow/dbt/weather_project
            - ./dbt/profiles:/home/airflow/.dbt
            - ./notebooks/gx:/opt/airflow/gx
        command: scheduler

    jupyter:
        image: jupyter/scipy-notebook:latest
        container_name: jupyter_lab
        ports:
            - "8888:8888"
        volumes:
            - ./notebooks:/home/jovyan/notebooks # 로컬의 notebooks 폴더를 컨테이너의 작업 폴더와 동기화
            - ./dbt:/home/jovyan/dbt # 로컬의 dbt 폴더를 컨테이너에 마운트하여 dbt 프로젝트를 관리
            - ./data:/opt/airflow/data # 로컬의 data 폴더를 컨테이너의 data 폴더와 동기화
        command: start-notebook.sh --NotebookApp.token='' # 비밀번호 없이 Jupyter Lab을 실행하는 명령어 , 로컬용

    metabase:
        image: metabase/metabase:latest
        container_name: metabase_dashboard
        ports:
            - "3000:3000"
        depends_on:
            - postgres

# Docker 볼륨을 최종적으로 정의하는 섹션. 데이터 영속성을 위해 사용
volumes:
    postgres_data:
    minio_data: